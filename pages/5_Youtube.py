import streamlit as st
from googleapiclient.discovery import build
import pandas as pd
from googleapiclient.errors import HttpError
from datetime import datetime, timedelta
import json
from collections import Counter
import re

# ì„¤ì •
API_KEY = 'AIzaSyDLY6YYLqiQ_8YXt5eGFUGIFYvzKaOi-Yk'
youtube = build('youtube', 'v3', developerKey=API_KEY)

st.set_page_config(page_title="Shorts ì£¼ì œ ë¶„ì„ê¸°", layout="wide")
st.title("ğŸ¯ ì‡¼ì¸  ë–¡ìƒ ìƒí™© ë¶„ì„ ë„êµ¬")
st.caption("ì–´ë–¤ ìƒí™©ì—ì„œ ì‚¬ëŒë“¤ì´ ë‚˜ê°€ì§€ ì•Šê³  ëê¹Œì§€ ë¨¸ë¬¼ë €ëŠ”ì§€ ë¶„ì„í•©ë‹ˆë‹¤.")

# ë‚´ë¶€ ê¸°ë³¸ ì„¤ì •ê°’
DEFAULT_DAYS = 14
DEFAULT_SUB_LIMIT = 100000
DEFAULT_MAX_RESULTS = 50

# ìƒë‹¨ ê²€ìƒ‰ ë°”
keyword = st.text_input("ë¶„ì„í•˜ê³  ì‹¶ì€ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: ì¼ìƒ ë¸Œì´ë¡œê·¸, ìš”ë¦¬ ê¿€íŒ, ê³µê° ìƒí™©ê·¹")

if st.button("ë°ì´í„° ë¶„ì„ ì‹œì‘"):
    if not keyword:
        st.warning("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        st.stop()
        
    try:
        published_after = (datetime.utcnow() - timedelta(days=DEFAULT_DAYS)).isoformat() + "Z"
        
        with st.spinner(f"'{keyword}' ì£¼ì œì˜ ê³ ìœ ì§€ìœ¨ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê³  ë¶„ì„í•˜ëŠ” ì¤‘..."):
            # 1. ì‡¼ì¸  ìœ„ì£¼ ê²€ìƒ‰
            search_response = youtube.search().list(
                q=keyword,
                part='snippet',
                maxResults=DEFAULT_MAX_RESULTS,
                type='video',
                videoDuration='short', 
                publishedAfter=published_after,
                order='viewCount'
            ).execute()

            video_ids = [item['id']['videoId'] for item in search_response['items']]
            channel_ids = [item['snippet']['channelId'] for item in search_response['items']]

            # 2. ì˜ìƒ ìƒì„¸ í†µê³„
            video_response = youtube.videos().list(
                part='statistics,snippet',
                id=','.join(video_ids)
            ).execute()

            # 3. ì±„ë„ ì •ë³´
            channel_response = youtube.channels().list(
                part='statistics,snippet',
                id=','.join(list(set(channel_ids)))
            ).execute()

            channel_info = {item['id']: {
                'subs': int(item['statistics'].get('subscriberCount', 1)),
                'title': item['snippet']['title']
            } for item in channel_response.get('items', [])}

            video_data = []
            words_list = []

            for v in video_response.get('items', []):
                stats = v.get('statistics', {})
                snippet = v.get('snippet', {})
                c_id = snippet.get('channelId')
                c_data = channel_info.get(c_id, {'subs': 1, 'title': 'ì•Œ ìˆ˜ ì—†ìŒ'})
                
                if c_data['subs'] <= DEFAULT_SUB_LIMIT:
                    views = int(stats.get('viewCount', 0))
                    likes = int(stats.get('likeCount', 0))
                    comments = int(stats.get('commentCount', 0))
                    subs = c_data['subs'] if c_data['subs'] > 0 else 1
                    
                    planning_score = round(views / subs, 2)
                    engagement_rate = round(((likes + comments) / views) * 100, 2) if views > 0 else 0
                    
                    title = snippet.get('title')
                    video_data.append({
                        "ë¨¸ë¬´ë¦„ ì ìˆ˜": engagement_rate,
                        "ê¸°íš ì ìˆ˜": planning_score,
                        "ì œëª©": title,
                        "ì¡°íšŒìˆ˜": views,
                        "ì±„ë„ëª…": c_data['title'],
                        "ë§í¬": f"https://youtu.be/{v['id']}"
                    })
                    # í‚¤ì›Œë“œ ì¶”ì¶œìš© (ì¡°ì‚¬ ë“± ì œì™¸í•˜ê³  2ê¸€ì ì´ìƒë§Œ)
                    clean_title = re.sub(r'[^\w\s]', '', title)
                    words_list.extend([w for w in clean_title.split() if len(w) > 1])

            if video_data:
                # íƒ­ êµ¬ì„±: ë°ì´í„°ì™€ ë¶„ì„ì„ ë¶„ë¦¬
                tab1, tab2 = st.tabs(["ğŸ“‘ ë¶„ì„ ì˜ìƒ ë¦¬ìŠ¤íŠ¸", "ğŸ” ì£¼ì œ ë° ìƒí™© ì§‘ì¤‘ ë¶„ì„"])

                with tab1:
                    st.subheader("ë°ì´í„° ê¸°ë°˜ ê³ ìœ ì§€ìœ¨ ì˜ìƒ")
                    df = pd.DataFrame(video_data).sort_values(by="ë¨¸ë¬´ë¦„ ì ìˆ˜", ascending=False)
                    display_df = df.copy()
                    display_df['ì¡°íšŒìˆ˜'] = display_df['ì¡°íšŒìˆ˜'].apply(lambda x: f"{x:,}")
                    st.dataframe(
                        display_df,
                        column_config={"ë§í¬": st.column_config.LinkColumn("ì˜ìƒ í™•ì¸")},
                        use_container_width=True,
                        hide_index=True
                    )

                with tab2:
                    st.subheader("ğŸ’¡ ì‹œì²­ìê°€ ë¨¸ë¬´ë¥¸ 'ìƒí™©' í‚¤ì›Œë“œ TOP 10")
                    top_words = Counter(words_list).most_common(10)
                    
                    # ì§€í‘œ ì‹œê°í™”
                    cols = st.columns(5)
                    for i, (word, count) in enumerate(top_words):
                        cols[i%5].metric(f"{i+1}ìœ„ í‚¤ì›Œë“œ", word, f"{count}ë²ˆ í¬ì°©")
                    
                    st.divider()
                    st.markdown("""
                    ### ğŸ§ ì–´ë–»ê²Œ í•´ì„í•˜ë‚˜ìš”?
                    1. **ìƒí™© í‚¤ì›Œë“œ**: ìœ„ í‚¤ì›Œë“œë“¤ì€ ì‹œì²­ìê°€ ëê¹Œì§€ ë³´ê³  ë°˜ì‘í•œ ì˜ìƒ ì œëª©ì— ê³µí†µì ìœ¼ë¡œ í¬í•¨ëœ ë‹¨ì–´ì…ë‹ˆë‹¤. 
                    2. **ë¨¸ë¬´ë¦„ì˜ ë¹„ë°€**: 'ì™œ', 'ë°©ë²•', 'ê²°êµ­', 'ì‹¤ì œ' ê°™ì€ ë‹¨ì–´ê°€ ë§ë‹¤ë©´ **ì„œì‚¬ì  ê¶ê¸ˆì¦**ì„ ìœ ë°œí•œ ê²ƒì´ê³ , íŠ¹ì • ëŒ€ìƒ(ì˜ˆ: 'ìì·¨ìƒ', 'ì§ì¥ì¸')ì´ ë§ë‹¤ë©´ **ê³µê°ëŒ€** í˜•ì„±ì— ì„±ê³µí•œ ìƒí™©ì…ë‹ˆë‹¤.
                    """)

            else:
                st.warning("ì¡°ê±´ì— ë§ëŠ” ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤.")

    except Exception as e:
        st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
